{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1342d5b7-469a-4617-bf2f-cc2e64580860",
   "metadata": {},
   "source": [
    "### 행렬 곱\n",
    "- 내적(inner product) 또는 닷 프로젝트(dot product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac551d4-1f05-4f9d-a6bc-0699c1458db7",
   "metadata": {},
   "source": [
    "### 행렬 곱 실습\n",
    "- matmul()\n",
    "- 행렬 간의 곱, 백터와 행렬의 곱\n",
    "- 1,2 차원 행렬 계산에 용이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72621ed8-dc0e-4bcf-a680-679977920ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.FloatTensor([[1,2],\n",
    "                     [3,4],\n",
    "                     [5,6]])\n",
    "y=torch.FloatTensor([[1,2],\n",
    "                     [1,2]])\n",
    "print(x.size(), y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed43076-92f6-4517-b4d1-14b9869dc7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]),\n",
       " tensor([[1., 2.],\n",
       "         [3., 4.],\n",
       "         [5., 6.]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=torch.matmul(x,y)\n",
    "x.size(), x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165bd6f-f3e1-4806-8951-25913abc4f8a",
   "metadata": {},
   "source": [
    "- bmm()\n",
    "- 딥러닝에서는 샘플들의 연산이 행렬곱일 떄, 여러 샘플을 병렬로 연산 가능(미니 배치)\n",
    "- 3차원 행렬 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d571dcec-29b7-41dd-a8c3-9057b8916eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.FloatTensor(3,3,2)\n",
    "y=torch.FloatTensor(3,2,3)\n",
    "z=torch.bmm(x,y)\n",
    "z.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e8099-a94a-44f0-9a71-23a12680ecc1",
   "metadata": {},
   "source": [
    "### 선형 계층\n",
    "- 학습: 모델을 통해 목표로 하는 함수 $f*$에 가까운 함수 $f$를 구하는 과정\n",
    "- 모델: 근사 함수 $f$를 계산하는 도구\n",
    "- 신경망으로 구현한 기본 모델 -> 선형 계층\n",
    "- 4개의 입력을 받아 3개의 출력을 반환하는 함수 => $f: R^4$ &rarr; $R^3$\n",
    "- 선형 계층: 행렬 곱셈(W)과 벡터의 덧셈(b)으로 이루어진 선형 변환\n",
    "- 대량의 데이터 -> 병렬 처리 -> 미니배치\n",
    "  - n차원의 특징 벡터로 구성된 샘플 N개를 모아서 행렬로 구성 &rarr; epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb141cb-6eb1-4c80-bc90-f9d4fe8c15fd",
   "metadata": {},
   "source": [
    "#### epoch\n",
    "- 훈련 데이터셋 전체가 신경망을 한 번 완전히 통과한 과정\n",
    "- ex) 데이터 셋의 크기: 1000개<br>\n",
    "  $\\quad$배치 크기: 100\n",
    "  - 1 epoch = 10번의 파라미터 업데이트(1000개의 데이터를 100개씩 10번 나눠서 학습)\n",
    "- 여러 epoch 동안 반복해서 데이터를 보게 하면서 점진적으로 오차(loss)를 줄임\n",
    "- 너무 많은 epoch을 돌리면 학습 데이터에 과적합될 수 있음  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d9ace3-0a37-4af5-8c81-c1ab7cefcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W=torch.FloatTensor([[1,2],[3,4],[5,6]])\n",
    "b=torch.FloatTensor([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b29b91-58d0-4114-9653-913c3675b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 계층 함수\n",
    "def linear(x,W,b):\n",
    "    y=torch.matmul(x,W)+b\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5daae762-a451-44e3-a3b7-0b41fa86b3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.FloatTensor(4,3)\n",
    "x # 무조건 0은 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cafe6295-df7f-4327-bfae-3e43eeae666f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=linear(x,W,b)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15082b9e-a31c-434c-bcef-8c8a2b35505e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8138e1e5-f607-45da-9e6d-27bbdd69bcdc",
   "metadata": {},
   "source": [
    "### torch.nn.Module 클래스 상속 받기\n",
    "- torch.nn: 신경망 패키지\n",
    "- Module: 신경망 구현을 위한 추상 클래스\n",
    "- Module 클래스를 상속 받으려면 2개의 메서드를 오버라이드 해야함\n",
    "  - \\_\\_init\\_\\_(): 계층에 필요한 변수 선언\n",
    "  - forward(): 계층을 통과하는데 필요한 계산 수행(순방향 전파)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8b4640-24f9-4cdf-ba29-5e95457bc0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyLinear(nn.Module): # nn.Module을 상속받아 만든 사용자 정의 선형 계층\n",
    "    def __init__(self, input_dim=3, output_dim=2): # 입력 차원, 출력 차원 정의 + 가중치/편향 초기화\n",
    "        self.input_dim=input_dim # 입력 벡터 차원(특징 개수)\n",
    "        self.output_dim=output_dim # 출력 벡터 차원\n",
    "\n",
    "        super().__init__() # 부모 클래스(nn.Module)의 생성자를 호출\n",
    "\n",
    "        self.W=torch.FloatTensor(input_dim, output_dim) # 가중치 행렬\n",
    "        self.b=torch.FloatTensor(output_dim) # 편향 행렬\n",
    "\n",
    "    def forward(self, x): # 입력 x에 대해 선형 변환 y = xW + b 수행(순전파)\n",
    "        # |x|=(batch_size,input_dim)\n",
    "        y=torch.matmul(x,self.W)+self.b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6547547d-a812-4692-afe0-bc3622c7a86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3425e+18, 2.1328e-42],\n",
       "        [2.3425e+18, 2.1328e-42],\n",
       "        [2.3425e+18, 2.1328e-42],\n",
       "        [2.3425e+18, 2.1328e-42]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear=MyLinear(3,2) # 변수 이름을 함수처럼 사용\n",
    "y=linear(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3464b389-b5ac-46e7-b7e9-3350d3baec11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3425e+18, 2.1328e-42],\n",
       "        [2.3425e+18, 2.1328e-42],\n",
       "        [2.3425e+18, 2.1328e-42],\n",
       "        [2.3425e+18, 2.1328e-42]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=linear.forward(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0671ca9-a2af-4b83-8570-41f9531f6a87",
   "metadata": {},
   "source": [
    "- forward() 함수를 따로 호출하지 않고 객체명에 바로 괄호를 열어 텐서 x를 인수로 넘겨줌\n",
    "  - \\_\\_call\\_\\_() 함수와 forward() 함수가 매핑되어 있음(자동 호출)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd506db-e853-4ac7-a575-3e0921558e75",
   "metadata": {},
   "source": [
    "### \\_\\_call\\_\\_(): 객체호출 메소드\n",
    "- \\_\\_call\\_\\_(): 클래스의 인스턴스를 생성(초기화)하는 메소드\n",
    "- \\_\\_init\\_\\_(): 인스턴스를 호출하는 메소드\n",
    "- \\_\\_init\\_\\_()에서 forward()를 호출하는 코드를 넣어두면 인스턴스를 호출할 때마다 forward()가 자동 호출됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63adeb4-10ba-417b-bd68-5f9dd9573d7b",
   "metadata": {},
   "source": [
    "### 올바른 방법: nn.Parameter 활용\n",
    "- 텐서를 만들어서 nn.Parameter로 넘겨줌\n",
    "  - pyTorch에서 학습할 때 전달되는 파라미터 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb12e29-5567-444a-82c7-830eb3170abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=2):\n",
    "        self.input_dim=input_dim\n",
    "        self.output_dim=output_dim\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # model.parameters()에 자동 등록되어 옵티마이저가 업데이트함\n",
    "        self.W=nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
    "        self.b=nn.Parameter(torch.FloatTensor(output_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size,input_dim)\n",
    "        # |W| = (input_dim, output_dim)\n",
    "        y=torch.matmul(x,self.W)+self.b # 브로드캐스팅으로 편향 추가\n",
    "        # |y| = (batch_size, output_dim)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c248d819-c21f-4dc4-868f-256c32a5cfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3425e+18, 0.0000e+00],\n",
       "        [2.3425e+18, 0.0000e+00],\n",
       "        [2.3425e+18, 0.0000e+00],\n",
       "        [2.3425e+18, 0.0000e+00]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear=MyLinear(3,2)\n",
    "y=linear(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9977bf7e-9722-48a4-a74c-5afa04512509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([2.3425e+18, 0.0000e+00], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in linear.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08d445bb-26d3-48af-be44-9d15157cc6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=2):\n",
    "        self.input_dim=input_dim\n",
    "        self.output_dim=output_dim\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear=nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # |x|=(batch_size,input_dim)\n",
    "        y=self.linear(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade6a818-271b-4dc7-ae87-f77871ee25e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6224,  0.0873],\n",
       "        [-0.8073,  1.3279],\n",
       "        [-0.2260,  0.6625],\n",
       "        [ 0.7383, -1.0155]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear=MyLinear(3,2)\n",
    "x = torch.randn(4, 3) # batch_size = 4, input_dim = 3\n",
    "y=linear(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ab2ad-70ca-4ec9-b6de-c0ba9512b739",
   "metadata": {},
   "source": [
    "### GPU 사용하기\n",
    "- CUDA를 통해 GPU 연산\n",
    "- 코랩 ㄱㄱ https://colab.research.google.com/?hl=ko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575942dc-52ec-4da5-94b7-fde6729d2597",
   "metadata": {},
   "source": [
    "### 평균 제곱 오차(MSE)\n",
    "- 모델에 데이터를 넣고 함수 $f$가 $f*$를 잘 근사하고 있는지 판단할 수 있어야 함\n",
    "- 데이터를 넣고 원하는 출력이 나오는지 확인 <- 수치해석(numerical analysis)적 방법\n",
    "- 손실(loss)값: 목표로 하는 출력(y)가 모델에 데이터를 넣어서 나오는 출력(y) 간의 차이의 크기를 모두 더한 것\n",
    "  - 손실이 적을수록 모델이 함수 $f*$에 잘 근사하고 있다고 판단 => 좋은 모델\n",
    "- 모델 함수는 가중치 파라미터(W, b)에 의해 동작이 정의됨\n",
    "  - $\\theta$로 정의: $\\theta$= { W, b }\n",
    "  - 모델 함수: $f_0$\n",
    "- 학습의 목적: 목표 함수 $f*$에 가장 근사한 모델의 함수 $f_0$을 찾는 것 => 즉, 손실값을 최소화하는 모델을 찾는 것\n",
    "  - 가장 단순한 방법: $\\theta$를 랜덤하게 바꿔보는 것\n",
    "- 얼마나 손실이 줄었는지 확인하는 방법: 손실함수의 결과값 확인\n",
    "  - 가중치 파라미너 세타를 입력하는 손실함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97ff28-191d-485c-82eb-2b9f6c482327",
   "metadata": {},
   "source": [
    "### 손실함수 선택\n",
    "- L1: 벡터의 각 요소들 사이의 차이에 대핸 절댓값을 모두 더함\n",
    "- L2: 유클리디안 거리(두 점 사이의 거리 계산)\n",
    "- RMSE: 제곱근 평균 제곱 오차(차이가 클 때 선택하면 좋음) => 불연속\n",
    "- MSE: 평균 제곱 오차(차이가 작을 때 선택하면 좋음) => 미분 가능(연속)\n",
    "- CE(책에 없음): 교차 엔트로피(계산한 확률 분포와 원하는 확률 분포의 차이를 계산)\n",
    "  - 손실함수의 최솟값 = CE의 최솟값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e6caed-2082-437b-8d78-6a58a88782c2",
   "metadata": {},
   "source": [
    "#### 엔트로피\n",
    "- 확률이 높으면 정보량이 낮음\n",
    "- 확률이 낮으면 정보량이 높음\n",
    "- but, 정보량이 0보다는 크거나 같음(음수는 절대 아님)<br>\n",
    "=> $log 1/Pi$ = $-log Pi$\n",
    "- $\\sum Pi$ $\\log\\frac{1}{pi}$ = $-Pi\\sum log Pi$\n",
    "- KL발산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a6fbe-972c-46b5-b95d-19929f431266",
   "metadata": {},
   "source": [
    "### 손실 함수가 필요한 이유\n",
    "- 신경망의 내부 가중치 파라미터를 조절해 함수를 근사계산할 수 있음\n",
    "- 얼마나 잘 근사계산하는지 알아야 더 좋은 가중치 파라미터를 선택할 수 있음\n",
    "- 손실 값은 얼마나 근사계산하는지 수치로 나타낸 것(낮을수록 좋음)\n",
    "- 선형 계층의 가중치 파라미터 변화에 따라 손실 값이 변할 것\n",
    "- 가중치 파라미터를 입력으로 받아 손실 값을 출력으로 반환하는 함수를 만들 수 있는데 이것이 손실임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee12d900-dd29-453e-b7e8-314180fbec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x_hat, x):\n",
    "    y=((x-x_hat)**2).mean()\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca663931-70fd-47d9-96d4-1c38bbbe5a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.FloatTensor([[1,1],[2,2]])\n",
    "x_hat=torch.FloatTensor([[0,0],[0,0]])\n",
    "mse(x_hat, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6fce61-99cc-435c-87eb-b3ae21f31548",
   "metadata": {},
   "source": [
    "### torch.nn.functional 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b720f926-23e7-4724-ba8a-af7a40e5ccc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as f\n",
    "f.mse_loss(x_hat, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d68b4a8-7d73-4688-b4ce-84e90300c6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.mse_loss(x_hat, x, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50720dd1-6f83-4c01-95f0-05065885eb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [4., 4.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.mse_loss(x_hat, x, reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235b844-bf16-4e41-9a5d-90e73fd9a946",
   "metadata": {},
   "source": [
    "### torch.nn. 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0c15b6e-f74b-4dde-a9b0-0de1ccfddf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "mse_loss = nn.MSELoss()\n",
    "mse_loss(x_hat, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ae9f2-9688-436f-98d2-f356e9285990",
   "metadata": {},
   "source": [
    "### 교차 엔트로피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fce5b0a6-7b7f-4554-8588-0f419f504f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0794)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.cross_entropy(x_hat, x)\n",
    "CE_loss = nn.CrossEntropyLoss()\n",
    "CE_loss(x_hat, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
